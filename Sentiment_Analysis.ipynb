{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "“Sentiment Analysis”的副本",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MwfoLyIvoj-c",
        "colab_type": "code",
        "outputId": "c8ce5033-f529-487f-de4d-007fa7eb6f97",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        }
      },
      "source": [
        "!wget \"https://www.dropbox.com/s/w03mdyw4kqimwgt/data.zip?dl=0\"\n",
        "!unzip data.zip\\?dl\\=0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-08-13 06:38:46--  https://www.dropbox.com/s/w03mdyw4kqimwgt/data.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.82.1, 2620:100:6032:1::a27d:5201\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.82.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: /s/raw/w03mdyw4kqimwgt/data.zip [following]\n",
            "--2019-08-13 06:38:47--  https://www.dropbox.com/s/raw/w03mdyw4kqimwgt/data.zip\n",
            "Reusing existing connection to www.dropbox.com:443.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://uceedcc6ef572d05d73085e27cdf.dl.dropboxusercontent.com/cd/0/inline/Amhj8zPwrSCdDZq1hZUSdo6Bd4LQGBchQvzIw5oT9ybBIh6wioutPGptPtoofGARAZ_NHeliDvh_XSq8w660XZUIrBEQbH2RcKgougyZ1QyHtbwK7y49bQJdE_RPDIe6k28/file# [following]\n",
            "--2019-08-13 06:38:47--  https://uceedcc6ef572d05d73085e27cdf.dl.dropboxusercontent.com/cd/0/inline/Amhj8zPwrSCdDZq1hZUSdo6Bd4LQGBchQvzIw5oT9ybBIh6wioutPGptPtoofGARAZ_NHeliDvh_XSq8w660XZUIrBEQbH2RcKgougyZ1QyHtbwK7y49bQJdE_RPDIe6k28/file\n",
            "Resolving uceedcc6ef572d05d73085e27cdf.dl.dropboxusercontent.com (uceedcc6ef572d05d73085e27cdf.dl.dropboxusercontent.com)... 162.125.82.6, 2620:100:6032:6::a27d:5206\n",
            "Connecting to uceedcc6ef572d05d73085e27cdf.dl.dropboxusercontent.com (uceedcc6ef572d05d73085e27cdf.dl.dropboxusercontent.com)|162.125.82.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 FOUND\n",
            "Location: /cd/0/inline2/AmiEIQ9e_vrl0e1Bb2kSVVRLws8EtjU7s1ylesUjYrKY-KJs8EE7CoTVKdsAmBJjwTPubyNKVK1646_gZG1rrQqJ_WvO3b-IO-Dt2YQ2ojG_D6HRmTeXZZ_fa8wBEoWa8z2l8-KSK6FKYOni-OMOpw2G0ndzWojZABNcVf62q5p455lNp1F1z83Bmkn2HVAOWhNCNrFNHTJE44QpjO291Uh-looKGx33a3rYE1O4UtyUHEQwlKLmSpFflJuIVXc2XeccY1tBfdlLt3WbhVbfJqsuB2AbJ0A13hsx2QJFIpiNwQnw8jBvjb1Rp7t4hLkzXFCgFMxoul89rMcrgiUKTnHtaVkXz_pVGU7etBXN3FwDUA/file [following]\n",
            "--2019-08-13 06:38:48--  https://uceedcc6ef572d05d73085e27cdf.dl.dropboxusercontent.com/cd/0/inline2/AmiEIQ9e_vrl0e1Bb2kSVVRLws8EtjU7s1ylesUjYrKY-KJs8EE7CoTVKdsAmBJjwTPubyNKVK1646_gZG1rrQqJ_WvO3b-IO-Dt2YQ2ojG_D6HRmTeXZZ_fa8wBEoWa8z2l8-KSK6FKYOni-OMOpw2G0ndzWojZABNcVf62q5p455lNp1F1z83Bmkn2HVAOWhNCNrFNHTJE44QpjO291Uh-looKGx33a3rYE1O4UtyUHEQwlKLmSpFflJuIVXc2XeccY1tBfdlLt3WbhVbfJqsuB2AbJ0A13hsx2QJFIpiNwQnw8jBvjb1Rp7t4hLkzXFCgFMxoul89rMcrgiUKTnHtaVkXz_pVGU7etBXN3FwDUA/file\n",
            "Reusing existing connection to uceedcc6ef572d05d73085e27cdf.dl.dropboxusercontent.com:443.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 11474769 (11M) [application/zip]\n",
            "Saving to: ‘data.zip?dl=0’\n",
            "\n",
            "data.zip?dl=0       100%[===================>]  10.94M  54.2MB/s    in 0.2s    \n",
            "\n",
            "2019-08-13 06:38:48 (54.2 MB/s) - ‘data.zip?dl=0’ saved [11474769/11474769]\n",
            "\n",
            "Archive:  data.zip?dl=0\n",
            "   creating: data/\n",
            "  inflating: data/test.csv           \n",
            "  inflating: data/train.csv          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8YITROzLPxT",
        "colab_type": "code",
        "outputId": "2d302d87-a246-4a0d-c561-63e62dda886a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import csv\n",
        "import torch\n",
        "import itertools\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class Voc:\n",
        "    def __init__(self, size=4, lines=[]):\n",
        "        assert size >= 4\n",
        "        self.index2word = {0: \"SOS\", 1: \"EOS\", 2:\"PAD\", 3:\"UNK\"}\n",
        "        word2count = {}\n",
        "        for l in lines:\n",
        "            for word in l.split(' '):\n",
        "                if word not in word2count:\n",
        "                    word2count[word] = 1\n",
        "                else:\n",
        "                    word2count[word] += 1\n",
        "        word2count = list(word2count.items())\n",
        "        word2count.sort(key=lambda x: x[1], reverse=True)\n",
        "        size = min(size, len(word2count))\n",
        "        if len(lines):\n",
        "            print(\"{} words trimmed to {} words\".format(len(word2count), size))\n",
        "        for i in range(size-4):\n",
        "            self.index2word[i+4] = word2count[i][0]\n",
        "        self.word2index = {v: k for k, v in self.index2word.items()}\n",
        "\n",
        "    def getIndex(self, word):\n",
        "        if word in self.word2index:\n",
        "            return self.word2index[word]\n",
        "        else:\n",
        "            return self.word2index[\"UNK\"]\n",
        "\n",
        "    def save2file(self, path):\n",
        "        with open(path, 'w') as f:\n",
        "            yaml.dump(self.index2word, f, default_flow_style=False, allow_unicode=True)\n",
        "\n",
        "    def load_file(self, path):\n",
        "        with open(path, 'r') as f:\n",
        "            self.index2word = yaml.load(f)\n",
        "            self.word2index = {v: k for k, v in self.index2word.items()}\n",
        "            self.size = len(self.index2word)\n",
        "\n",
        "class Twit_dataset(Dataset):\n",
        "    def __init__(self, csv_file, voc):\n",
        "        with open(csv_file) as f:\n",
        "            reader = csv.reader(f)\n",
        "            self.data = list(reader)\n",
        "        self.data = [(int(d[0]), [voc.getIndex(w) for w in d[1]]) for d in self.data]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "def collate_fn(batch):\n",
        "    def pad(seqs, fillvalue=2):\n",
        "        tmp = list(itertools.zip_longest(*seqs, fillvalue=fillvalue))\n",
        "        return torch.LongTensor(tmp)\n",
        "    ys, xs = list(zip(*batch))\n",
        "    xs = pad(xs)\n",
        "    return torch.LongTensor(xs), torch.FloatTensor(ys)\n",
        "\n",
        "seqs = []\n",
        "size = 20000\n",
        "with open('data/train.csv') as f:\n",
        "    reader = csv.reader(f)\n",
        "    for r in reader:\n",
        "        seqs.append(r[1])\n",
        "voc = Voc(size, seqs)\n",
        "train_dataset = Twit_dataset('data/train.csv', voc)\n",
        "valid_dataset = Twit_dataset('data/test.csv', voc)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=1, collate_fn=collate_fn)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False, num_workers=1, collate_fn=collate_fn)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "82945 words trimmed to 20000 words\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6UJogaKs2gS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class My_model(nn.Module):\n",
        "    def __init__(self, n_layers, voc_size, dropout=0.2):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(voc_size, 256)\n",
        "        self.rnn = nn.GRU(256, 256, n_layers, dropout=dropout)\n",
        "        self.fc = nn.Linear(256, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        emb = self.embedding(x)\n",
        "        output, hidden = self.rnn(emb)\n",
        "        output = self.fc(output[-1])\n",
        "        return torch.sigmoid(output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yEikpXt02XJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = 'cuda'\n",
        "n_epoch = 5\n",
        "model = My_model(2, 20000).to(device)\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "print_loss = 0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJfZLNYF2zGw",
        "colab_type": "code",
        "outputId": "f44c1953-a438-4cb0-9457-e72d4e42ee1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for e in range(n_epoch):\n",
        "    print('============= Epoch: {} ============='.format(e+1))\n",
        "    for idx, (x, y) in enumerate(train_loader):\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        o = model(x)\n",
        "        loss = criterion(o.squeeze(), y)\n",
        "        print_loss += loss.item()\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (idx+1) % 100 == 0:\n",
        "            print('loss:', print_loss/100)\n",
        "            print_loss = 0.0\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "============= Epoch: 1 =============\n",
            "loss: 0.5047378954291344\n",
            "loss: 0.3942653985321522\n",
            "loss: 0.3876168209314346\n",
            "loss: 0.40268398225307467\n",
            "loss: 0.4069484996795654\n",
            "loss: 0.39989668875932693\n",
            "loss: 0.39441015258431433\n",
            "loss: 0.4004122844338417\n",
            "loss: 0.3985528263449669\n",
            "loss: 0.41054607152938843\n",
            "loss: 0.40015999257564544\n",
            "loss: 0.4140382158756256\n",
            "loss: 0.4008857062458992\n",
            "loss: 0.40533855006098746\n",
            "loss: 0.38861322045326235\n",
            "loss: 0.42293769747018817\n",
            "loss: 0.3954067088663578\n",
            "loss: 0.4058258217573166\n",
            "loss: 0.4146680372953415\n",
            "loss: 0.41023378729820253\n",
            "loss: 0.40644326478242876\n",
            "loss: 0.4084769403934479\n",
            "loss: 0.4092845797538757\n",
            "loss: 0.41397729963064195\n",
            "loss: 0.39755660921335223\n",
            "loss: 0.40115255922079085\n",
            "loss: 0.4120865029096603\n",
            "loss: 0.4165258812904358\n",
            "loss: 0.3999462580680847\n",
            "loss: 0.4145052808523178\n",
            "loss: 0.40048198208212854\n",
            "============= Epoch: 2 =============\n",
            "loss: 0.48043680131435396\n",
            "loss: 0.3858619250357151\n",
            "loss: 0.4034507718682289\n",
            "loss: 0.39701565831899643\n",
            "loss: 0.3904173263907433\n",
            "loss: 0.40349579572677613\n",
            "loss: 0.40099132925271985\n",
            "loss: 0.3928798070549965\n",
            "loss: 0.38932120144367216\n",
            "loss: 0.39816200524568557\n",
            "loss: 0.40044674292206767\n",
            "loss: 0.4041875267028809\n",
            "loss: 0.4088123574852943\n",
            "loss: 0.4021563938260078\n",
            "loss: 0.39878515273332593\n",
            "loss: 0.4072058334946632\n",
            "loss: 0.4057395777106285\n",
            "loss: 0.3957325381040573\n",
            "loss: 0.39029819682240485\n",
            "loss: 0.3980775395035744\n",
            "loss: 0.40358139723539355\n",
            "loss: 0.39978003084659575\n",
            "loss: 0.41387374579906466\n",
            "loss: 0.4025498032569885\n",
            "loss: 0.40655515700578687\n",
            "loss: 0.4017899689078331\n",
            "loss: 0.4053203547000885\n",
            "loss: 0.4008163720369339\n",
            "loss: 0.400929478853941\n",
            "loss: 0.4226975443959236\n",
            "loss: 0.4005346965789795\n",
            "============= Epoch: 3 =============\n",
            "loss: 0.4865203168988228\n",
            "loss: 0.3813013814389706\n",
            "loss: 0.3759705539047718\n",
            "loss: 0.38609389185905457\n",
            "loss: 0.3946045050024986\n",
            "loss: 0.39705523431301115\n",
            "loss: 0.3933158138394356\n",
            "loss: 0.40119813293218615\n",
            "loss: 0.4008267840743065\n",
            "loss: 0.4026482480764389\n",
            "loss: 0.3999297869205475\n",
            "loss: 0.39025261789560317\n",
            "loss: 0.3967828440666199\n",
            "loss: 0.40172933250665666\n",
            "loss: 0.4039745962619781\n",
            "loss: 0.3943309752643108\n",
            "loss: 0.3978368937969208\n",
            "loss: 0.40817258358001707\n",
            "loss: 0.4025906378030777\n",
            "loss: 0.39971441417932513\n",
            "loss: 0.40703817188739777\n",
            "loss: 0.39841451242566106\n",
            "loss: 0.38769530460238455\n",
            "loss: 0.3959094850718975\n",
            "loss: 0.39841090321540834\n",
            "loss: 0.4068244042992592\n",
            "loss: 0.40226996928453446\n",
            "loss: 0.4038946309685707\n",
            "loss: 0.410269170999527\n",
            "loss: 0.41223450541496276\n",
            "loss: 0.40520815819501876\n",
            "============= Epoch: 4 =============\n",
            "loss: 0.48981955587863923\n",
            "loss: 0.3747334671020508\n",
            "loss: 0.38335881635546687\n",
            "loss: 0.3884919965267181\n",
            "loss: 0.388616641163826\n",
            "loss: 0.39284133166074753\n",
            "loss: 0.3980978339910507\n",
            "loss: 0.3991275765001774\n",
            "loss: 0.39131943836808203\n",
            "loss: 0.37824891865253446\n",
            "loss: 0.3994713154435158\n",
            "loss: 0.4012554582953453\n",
            "loss: 0.3914766451716423\n",
            "loss: 0.402125696092844\n",
            "loss: 0.3953560598194599\n",
            "loss: 0.39941993713378904\n",
            "loss: 0.4079052940011024\n",
            "loss: 0.39852882355451585\n",
            "loss: 0.39510854870080947\n",
            "loss: 0.39583577767014505\n",
            "loss: 0.39920706406235695\n",
            "loss: 0.40259341925382613\n",
            "loss: 0.40793689355254176\n",
            "loss: 0.3975274369120598\n",
            "loss: 0.4107308439910412\n",
            "loss: 0.4095407176017761\n",
            "loss: 0.39720101803541186\n",
            "loss: 0.4005571202933788\n",
            "loss: 0.3903757435083389\n",
            "loss: 0.4043692168593407\n",
            "loss: 0.40247352510690687\n",
            "============= Epoch: 5 =============\n",
            "loss: 0.4868868072330952\n",
            "loss: 0.39048957481980323\n",
            "loss: 0.38693862825632097\n",
            "loss: 0.3713779392838478\n",
            "loss: 0.3908500528335571\n",
            "loss: 0.39440029993653297\n",
            "loss: 0.3944178745150566\n",
            "loss: 0.40032923221588135\n",
            "loss: 0.3868742011487484\n",
            "loss: 0.3877763137221336\n",
            "loss: 0.386531013995409\n",
            "loss: 0.3990680733323097\n",
            "loss: 0.4027294358611107\n",
            "loss: 0.4005748224258423\n",
            "loss: 0.3719507645070553\n",
            "loss: 0.3856026974320412\n",
            "loss: 0.4115748935937881\n",
            "loss: 0.3975854931771755\n",
            "loss: 0.3924886268377304\n",
            "loss: 0.38982740104198454\n",
            "loss: 0.3837303149700165\n",
            "loss: 0.4052767765522003\n",
            "loss: 0.40306527793407443\n",
            "loss: 0.40330387741327284\n",
            "loss: 0.40040688559412957\n",
            "loss: 0.3979067975282669\n",
            "loss: 0.4006920644640923\n",
            "loss: 0.3938747635483742\n",
            "loss: 0.39852514266967776\n",
            "loss: 0.4034949642419815\n",
            "loss: 0.4160383793711662\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}